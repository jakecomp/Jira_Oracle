{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#%pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from tensorboard.plugins import projector\n",
    "## Load in data\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "tickets = pd.read_csv(\"master_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files.\n",
    "log_dir_encode='mlogs/encode_data'\n",
    "if not os.path.exists(log_dir_encode):\n",
    "    os.makedirs(log_dir_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/birdy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/birdy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/birdy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bagOfWordsEncoder(vocab, input):\n",
    "    ## Make an array size of the vocab\n",
    "    encoderMatrix = np.zeros(len(vocab))\n",
    "\n",
    "    ## Iterate the input strings and encode their position in the array\n",
    "    for word in input:\n",
    "        index = vocab[vocab['word']==word].index.values\n",
    "        encoderMatrix[index] += 1\n",
    "    \n",
    "    if encoderMatrix.std() != 0:\n",
    "        encoderMatrix = (encoderMatrix - encoderMatrix.mean()) / encoderMatrix.std()\n",
    "    return encoderMatrix\n",
    "\n",
    "## Method for getting input\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def parse_text(text):\n",
    "\n",
    "    ## Tokenize string into words (and punctuation)\n",
    "    word_array = word_tokenize(text)\n",
    "    word_array = [word.lower() for word in word_array if word.isalpha()]\n",
    "\n",
    "    ## Filter out stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in word_array if word.casefold() not in stop_words]\n",
    "\n",
    "    ## Turn words into lemmatized words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemitized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "\n",
    "    ## Apply Stemming (Find the roots of similar words)\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in lemitized_words]\n",
    "\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab = pd.read_csv(\"reduced_vocabulary.csv\")\n",
    "#vocab = vocab['word'].tolist()\n",
    "encodings = []\n",
    "efforts = tickets['effort(s)'].to_numpy()\n",
    "\n",
    "## Count tickets\n",
    "\n",
    "descs = tickets['desc'].to_numpy()\n",
    "for desc in descs:\n",
    "    parsed = parse_text(desc)\n",
    "    encoding = bagOfWordsEncoder(vocab, parsed)\n",
    "    encodings.append(encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19000\n",
      "19000\n",
      "19000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 04:25:16.910001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 04:25:16.985297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 04:25:16.985356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 04:25:16.990997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 04:25:16.991045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 04:25:16.991072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 04:25:25.981896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 04:25:25.982002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 04:25:25.982031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-28 04:25:25.982067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-28 04:25:25.982177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20066 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:0b:00.0, compute capability: 8.9\n",
      "2023-07-28 04:25:25.994011: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1000281600 exceeds 10% of free system memory.\n",
      "2023-07-28 04:35:49.058305: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 250070400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Gather training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "labels = pd.read_csv(\"labelled_dataset.csv\")\n",
    "\n",
    "labels = labels['Grade'].tolist()\n",
    "labels = [(label - 1)/2 for label in labels]\n",
    "\n",
    "data = {'encoding': encodings, 'effort': labels}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "## simplify data ~ 10000\n",
    "df_low_effort = df[df.effort == 0.0].sample(19000)\n",
    "df_med_effort = df[df.effort == 0.5].sample(19000)\n",
    "df_hig_effort = df[df.effort == 1.0].sample(19000)\n",
    "\n",
    "print(len(df_low_effort))\n",
    "print(len(df_med_effort))\n",
    "print(len(df_hig_effort))\n",
    "\n",
    "result = pd.concat([df_low_effort, df_med_effort, df_hig_effort], axis=0)\n",
    "\n",
    "train, test = train_test_split(result, test_size=0.2, shuffle=True)\n",
    "\n",
    "x_train = tf.convert_to_tensor(train['encoding'].to_list())\n",
    "y_train = tf.convert_to_tensor(train['effort'])\n",
    "\n",
    "x_test = tf.convert_to_tensor(test['encoding'].to_list())\n",
    "y_test = tf.convert_to_tensor(test['effort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f261f3ab02ac6284\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f261f3ab02ac6284\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logdir = os.path.join(\"mlogs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "2023-07-28 04:55:38.348579: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1000281600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9600f0c400> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x7f9600f0c400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9600f0c400> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x7f9600f0c400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9600f0c400> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x7f9600f0c400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7f95fa09e2f0>> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7f95fa09e2f0>>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7f95fa09e2f0>> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7f95fa09e2f0>>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7f95fa09e2f0>> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7f95fa09e2f0>>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 04:55:58.528937: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-28 04:55:59.018874: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f93d15a0970 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-28 04:55:59.018930: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2023-07-28 04:55:59.341072: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-28 04:56:01.413993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8903\n",
      "2023-07-28 04:56:01.830826: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-28 04:56:02.058994: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425/1425 [==============================] - 24s 4ms/step - loss: 0.1588 - accuracy: 0.4303\n",
      "Epoch 2/20\n",
      "   1/1425 [..............................] - ETA: 5s - loss: 0.0861 - accuracy: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 04:56:08.722393: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 168468480 exceeds 10% of free system memory.\n",
      "2023-07-28 04:56:08.867115: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31457280 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425/1425 [==============================] - 6s 4ms/step - loss: 0.1275 - accuracy: 0.5014\n",
      "Epoch 3/20\n",
      "1425/1425 [==============================] - 6s 4ms/step - loss: 0.0995 - accuracy: 0.5597\n",
      "Epoch 4/20\n",
      "1425/1425 [==============================] - 6s 4ms/step - loss: 0.0653 - accuracy: 0.6191\n",
      "Epoch 5/20\n",
      "1425/1425 [==============================] - 6s 4ms/step - loss: 0.0436 - accuracy: 0.6435\n",
      "Epoch 6/20\n",
      "1425/1425 [==============================] - 7s 5ms/step - loss: 0.0336 - accuracy: 0.6532\n",
      "Epoch 7/20\n",
      "1425/1425 [==============================] - 6s 4ms/step - loss: 0.0289 - accuracy: 0.6553\n",
      "Epoch 8/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0255 - accuracy: 0.6573\n",
      "Epoch 9/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0235 - accuracy: 0.6567\n",
      "Epoch 10/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0206 - accuracy: 0.6579\n",
      "Epoch 11/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0183 - accuracy: 0.6590\n",
      "Epoch 12/20\n",
      "1425/1425 [==============================] - 6s 4ms/step - loss: 0.0172 - accuracy: 0.6587\n",
      "Epoch 13/20\n",
      "1425/1425 [==============================] - 6s 4ms/step - loss: 0.0160 - accuracy: 0.6590\n",
      "Epoch 14/20\n",
      "1425/1425 [==============================] - 6s 4ms/step - loss: 0.0149 - accuracy: 0.6591\n",
      "Epoch 15/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0148 - accuracy: 0.6590\n",
      "Epoch 16/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0136 - accuracy: 0.6595\n",
      "Epoch 17/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0126 - accuracy: 0.6596\n",
      "Epoch 18/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0121 - accuracy: 0.6594\n",
      "Epoch 19/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0119 - accuracy: 0.6599\n",
      "Epoch 20/20\n",
      "1425/1425 [==============================] - 5s 4ms/step - loss: 0.0113 - accuracy: 0.6593\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f95fa06a200> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x7f95fa06a200>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f95fa06a200> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x7f95fa06a200>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f95fa06a200> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x7f95fa06a200>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "357/357 [==============================] - 1s 3ms/step - loss: 0.1851 - accuracy: 0.4390\n",
      "Tested Acc:  0.4390350878238678\n"
     ]
    }
   ],
   "source": [
    "## SETUP NEURAL NETWORK\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(2742,1)),\n",
    "    \n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    #keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    #keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(512, activation=\"relu\"),\n",
    "\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.1), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, shuffle=True,callbacks=[tensorboard_callback])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Tested Acc: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b' 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0\\r\\nAccept: text/html,']\n",
      "Bad pipe message: %s [b'plication/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\\r\\nAccept-Language: en-C']\n",
      "Bad pipe message: %s [b'en-US;q=0.7,en;q=0.3\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nConnec']\n",
      "Bad pipe message: %s [b'(Windows NT 10.0; Win64; x64; rv:109.0) Gecko/2']\n",
      "Bad pipe message: %s [b'00101 Firefox/115.0\\r\\nAccept: image/avif,image/w', b'p,*/*\\r\\nAccept-Language: en-CA,en-US;q=0.7,en;q=0.3\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nConnection: ']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save Labels separately on a line-by-line manner.\n",
    "\n",
    "with open(os.path.join(log_dir_encode, 'metadata.tsv'), \"w\") as f:\n",
    "  for subwords in encodings:\n",
    "    f.write(\"{}\\n\".format(subwords))\n",
    "  # Fill in the rest of the labels with \"unknown\".\n",
    "  for unknown in range(1, len(vocab) - len(encodings)):\n",
    "    f.write(\"unknown #{}\\n\".format(unknown))\n",
    "\n",
    "\n",
    "\n",
    "weights = tf.Variable(model.layers[0].get_weights()[1:])\n",
    "\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir_encode, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir_encode, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
