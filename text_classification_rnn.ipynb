{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4n9TsbGw-f"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2VQo4bajwUU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "z682XYsrjkY9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re   \n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras_nlp\n",
        "import keras_tuner\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rXHa-w9JZhb"
      },
      "source": [
        "Import `matplotlib` and create a helper function to plot graphs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Mp1Z7P9pYRSK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## Method for getting input\n",
        "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "# from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "# from nltk.corpus import stopwords\n",
        "# import nltk\n",
        "# nltk.download(\"punkt\")\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download(\"stopwords\")\n",
        "\n",
        "# def parse_text(text):\n",
        "\n",
        "#     ## Tokenize string into words (and punctuation)\n",
        "#     word_array = word_tokenize(text)\n",
        "#     word_array = [word.lower() for word in word_array if word.isalpha()]\n",
        "\n",
        "#     ## Filter out stop words\n",
        "#     stop_words = set(stopwords.words(\"english\"))\n",
        "#     filtered_words = [word for word in word_array if word.casefold() not in stop_words]\n",
        "\n",
        "#     ## Turn words into lemmatized words\n",
        "#     lemmatizer = WordNetLemmatizer()\n",
        "#     lemitized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "#     ## Apply Stemming (Find the roots of similar words)\n",
        "#     stemmer = PorterStemmer()\n",
        "#     stemmed_words = [stemmer.stem(word) for word in lemitized_words]\n",
        "\n",
        "#     joined_words = \"\"\n",
        "#     #for word in stemmed_words:\n",
        "#     joined_words = \" \".join(list(stemmed_words))\n",
        "#     return joined_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###makes clean file\n",
        "\n",
        "# import csv\n",
        "# csv.field_size_limit(10000000)\n",
        "# text_list = []\n",
        "# with open(\"master_dataset.csv\", newline='') as f:\n",
        "#     #reader = csv.reader(f)\n",
        "#     data = list(csv.reader(f))\n",
        "# #print(data[:10])\n",
        "# for row in data:\n",
        "    \n",
        "#     #print(parse_text(row[2]))\n",
        "#     text_list.append(str(parse_text(row[2])))\n",
        "\n",
        "# #print(text_list[:10])\n",
        "# with open(\"master_dataset_clean.csv\", 'w') as f2:\n",
        "#     #writer = csv.writer(f2)\n",
        "#     for x in text_list:\n",
        "#         f2.write(x)\n",
        "#         f2.write('\\n')\n",
        "        #writer.writerows([row])\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "tickets = pd.read_csv(\"master_dataset_clean.csv\", skip_blank_lines = False, keep_default_na=False)\n",
        "tickets = tickets.fillna('[UNK]')\n",
        "tickets2 = pd.read_csv(\"labelled_dataset.csv\")\n",
        "tickets3 = pd.DataFrame()\n",
        "\n",
        "#print(tickets['desc'][:3])\n",
        "#tickets['desc'] = [parse_text(text) for text in tickets['desc']]\n",
        "#tickets['desc'] = tickets['desc'].apply(parse_text())\n",
        "#print(tickets['desc'][:3])\n",
        "\n",
        "text_column = tickets['desc']\n",
        "tickets3 = pd.concat([tickets3,text_column], axis = 1)\n",
        "label_column = tickets2['Grade'].astype(int)\n",
        "label_column = label_column - 1\n",
        "tickets3 = pd.concat([tickets3,label_column], axis = 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(text_column, label_column, test_size=0.2, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True)\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 3)\n",
        "y_test_cat = to_categorical(y_test, 3)\n",
        "y_val_cat = to_categorical(y_val, 3)\n",
        "\n",
        "\n",
        "X_train_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "X_test_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "X_val_dataset = tf.data.Dataset.from_tensor_slices(X_val)\n",
        "# y_train_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "# y_test_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
        "y_train_dataset = tf.data.Dataset.from_tensor_slices(y_train_cat)\n",
        "y_test_dataset = tf.data.Dataset.from_tensor_slices(y_test_cat)\n",
        "y_val_dataset = tf.data.Dataset.from_tensor_slices(y_val_cat)\n",
        "\n",
        "test_dataset = tf.data.Dataset.zip((X_test_dataset, y_test_dataset))\n",
        "train_dataset = tf.data.Dataset.zip((X_train_dataset, y_train_dataset))\n",
        "val_dataset = tf.data.Dataset.zip((X_val_dataset, y_val_dataset))\n",
        "\n",
        "# print(train_dataset.element_spec)\n",
        "# print(test_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX2G_saMwWt-",
        "outputId": "ceaf8303-1037-4027-ef93-cf06a9ba64d9"
      },
      "outputs": [],
      "source": [
        "np.array(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd4_BGKyurao",
        "outputId": "3106e4b1-66e8-4b85-df7b-8b4ef39c47af"
      },
      "outputs": [],
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2qVJzcEluH_"
      },
      "source": [
        "Next shuffle the data for training and create batches of these `(text, label)` pairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dDsCaZCDYZgm"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000 #10000\n",
        "BATCH_SIZE = 128 #64\n",
        "VOCAB_SIZE = 2500 #1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VznrltNOnUc5"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqkvdcFv41wC",
        "outputId": "5208d200-8f62-46eb-b038-6f2dd7124dca"
      },
      "outputs": [],
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5eWCo88voPY"
      },
      "source": [
        "## Create the text encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFevcItw15P_"
      },
      "source": [
        "The raw text loaded by `tfds` needs to be processed before it can be used in a model. The simplest way to process text for training is using the `TextVectorization` layer. This layer has many capabilities, but this tutorial sticks to the default behavior.\n",
        "\n",
        "Create the layer, and pass the dataset's text to the layer's `.adapt` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC25Lu1Yvuqy"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 2500 #1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuQzVBbe3Ldu"
      },
      "source": [
        "The `.adapt` method sets the layer's vocabulary. Here are the first 20 tokens. After the padding and unknown tokens they're sorted by frequency:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBoyjjWg0Ac9",
        "outputId": "a56ca642-7a69-4820-b723-74d3220a2683"
      },
      "outputs": [],
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjId5pua3jHQ"
      },
      "source": [
        "Once the vocabulary is set, the layer can encode text into indices. The tensors of indices are 0-padded to the longest sequence in the batch (unless you set a fixed `output_sequence_length`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGc7C9WiwRWs",
        "outputId": "09b2b8a6-8eb2-48ba-b080-a9e6b0ca03fd"
      },
      "outputs": [],
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_tD0QY5wXaK",
        "outputId": "816a4547-4c2e-4097-8c94-0f03180ad3a0"
      },
      "outputs": [],
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", example[n].numpy())\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjUqGVBxGw-t"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgs6nnSTGw-t"
      },
      "source": [
        "Above is a diagram of the model.\n",
        "\n",
        "1. This model can be build as a `tf.keras.Sequential`.\n",
        "\n",
        "2. The first layer is the `encoder`, which converts the text to a sequence of token indices.\n",
        "\n",
        "3. After the encoder is an embedding layer. An embedding layer stores one vector per word. When called, it converts the sequences of word indices to sequences of vectors. These vectors are trainable. After training (on enough data), words with similar meanings often have similar vectors.\n",
        "\n",
        "  This index-lookup is much more efficient than the equivalent operation of passing a one-hot encoded vector through a `tf.keras.layers.Dense` layer.\n",
        "\n",
        "4. A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their input on the next timestep.\n",
        "\n",
        "  The `tf.keras.layers.Bidirectional` wrapper can also be used with an RNN layer. This propagates the input forward and backwards through the RNN layer and then concatenates the final output.\n",
        "\n",
        "  * The main advantage of a bidirectional RNN is that the signal from the beginning of the input doesn't need to be processed all the way through every timestep to affect the output.  \n",
        "\n",
        "  * The main disadvantage of a bidirectional RNN is that you can't efficiently stream predictions as words are being added to the end.\n",
        "\n",
        "5. After the RNN has converted the sequence to a single vector the two `layers.Dense` do some final processing, and convert from this vector representation to a single logit as the classification output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4fodCI7soQi"
      },
      "source": [
        "The code to implement this is below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwfoBkmRYcP3"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#     encoder,\n",
        "#     tf.keras.layers.Embedding(\n",
        "#         input_dim=len(encoder.get_vocabulary()),\n",
        "#         output_dim=64,\n",
        "#         # Use masking to handle the variable sequence lengths\n",
        "#         mask_zero=True),\n",
        "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "#     tf.keras.layers.Dense(64, activation='relu'),\n",
        "#     #tf.keras.layers.Dense(1)\n",
        "#     tf.keras.layers.Dense(3, activation='softmax')\n",
        "# ])\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    #keras_nlp.layers.FNetEncoder(intermediate_dim=64),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIGmIGkkouUb"
      },
      "source": [
        "Please note that Keras sequential model is used here since all the layers in the model only have single input and produce single output. In case you want to use stateful RNN layer, you might want to build your model with Keras functional API or model subclassing so that you can retrieve and reuse the RNN layer states. Please check [Keras RNN guide](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF-PsCk1LwjY"
      },
      "source": [
        "The embedding layer [uses masking](https://www.tensorflow.org/guide/keras/masking_and_padding) to handle the varying sequence-lengths. All the layers after the `Embedding` support masking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87a8-CwfKebw",
        "outputId": "ac262fcd-bc91-4e22-80ad-0dd4e0de5b51"
      },
      "outputs": [],
      "source": [
        "print([layer.supports_masking for layer in model.layers])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlS0iaUIWLpI"
      },
      "source": [
        "To confirm that this works as expected, evaluate a sentence twice. First, alone so there's no padding to mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O41gw3KfWHus",
        "outputId": "e26e436a-617a-4368-9722-a0e176b86793"
      },
      "outputs": [],
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0VQmGnEWcuz"
      },
      "source": [
        "Now, evaluate it again in a batch with a longer sentence. The result should be identical:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIgpuTeFNDzq",
        "outputId": "943c7c80-0979-438c-a9ce-9ec972577b80"
      },
      "outputs": [],
      "source": [
        "# predict on a sample text with padding\n",
        "\n",
        "padding = \"the \" * 2000\n",
        "predictions = model.predict(np.array([sample_text, padding]))\n",
        "print(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRI776ZcH3Tf"
      },
      "source": [
        "Compile the Keras model to configure the training process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj2xei41YZjC"
      },
      "outputs": [],
      "source": [
        "# model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "#               optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    #optimizer=tf.keras.optimizers.SGD(),\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    metrics=[\"accuracy\"] #tf.keras.metrics.CategoricalAccuracy()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIwH3nto596k"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#find weights for labels\n",
        "\n",
        "samp0 = 54046\n",
        "samp1 = 24077\n",
        "samp2 = 9863\n",
        "tot_samples = samp0 + samp1 + samp2\n",
        "\n",
        "w0 = tot_samples / (3*samp0)\n",
        "w1 = tot_samples / (3*samp1)\n",
        "w2 = tot_samples / (3*samp2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw86wWS4YgR2",
        "outputId": "cd7c3836-389f-4fee-8ed4-9203c5bd034c"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, \n",
        "                    epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30,\n",
        "                    #class_weight = {0:w0,1:w1,2:w2},\n",
        "                    #use_multiprocessing = True,\n",
        "                    #workers = 5\n",
        "                    )\n",
        "#class weight has made it worse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaNbXi43YgUT",
        "outputId": "8433bfa2-58eb-4c92-d8e7-48f88cf185e3"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "OZmwt_mzaQJk",
        "outputId": "d2c660e9-dff7-4bc7-bda7-370d8574992c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.ylim(None, 1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n",
        "plt.ylim(0, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXgfQSgRW6zU",
        "outputId": "818068a0-0550-4ba3-d4d7-4f362fee68e6"
      },
      "outputs": [],
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykUKnAoqbycW"
      },
      "outputs": [],
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was not good. The animation and the graphics '\n",
        "               'were terrible. I would not recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "print(np.argsmax(predictions[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-21 19:28:40.857703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [63349]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-07-21 19:28:40.857948: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [63349]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        }
      ],
      "source": [
        "train_dataset1 = train_dataset.shuffle(BUFFER_SIZE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset1 = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset1 = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "VOCAB_SIZE = 2500 #1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset1.map(lambda text, label: text))\n",
        "\n",
        "\n",
        "# train_dataset2 = train_dataset.shuffle(512).prefetch(16).cache()\n",
        "# test_dataset2 = test_dataset.shuffle(512).prefetch(16).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_1 (TextV  (None, None)             0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 8)           20000     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 8)                416       \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " f_net_encoder_3 (FNetEncode  (None, 8)                176       \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_4 (FNetEncode  (None, 8)                176       \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_5 (FNetEncode  (None, 8)                176       \n",
            " r)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_1 (TextV  (None, None)             0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 8)           20000     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 8)                416       \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " f_net_encoder_3 (FNetEncode  (None, 8)                176       \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_4 (FNetEncode  (None, 8)                176       \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_5 (FNetEncode  (None, 8)                176       \n",
            " r)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,971\n",
            "Trainable params: 20,971\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# model2 = tf.keras.Sequential([\n",
        "#     encoder,\n",
        "#     tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 128, mask_zero=True),\n",
        "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "#     keras_nlp.layers.FNetEncoder(intermediate_dim=128),\n",
        "#     keras_nlp.layers.FNetEncoder(intermediate_dim=128),\n",
        "#     keras_nlp.layers.FNetEncoder(intermediate_dim=128),\n",
        "#     tf.keras.layers.Dropout(0.1),\n",
        "#     tf.keras.layers.Dense(3, activation='softmax')\n",
        "# ])\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 8, mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(4)),\n",
        "    keras_nlp.layers.FNetEncoder(intermediate_dim=8),\n",
        "    keras_nlp.layers.FNetEncoder(intermediate_dim=8),\n",
        "    keras_nlp.layers.FNetEncoder(intermediate_dim=8),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "# input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
        "# x = encoder((input_ids))\n",
        "# # x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "# #     vocabulary_size=VOCAB_SIZE,\n",
        "# #     sequence_length=512,\n",
        "# #     embedding_dim=128,\n",
        "# #     mask_zero=True,\n",
        "# # )(input_ids)\n",
        "\n",
        "# x = keras_nlp.layers.FNetEncoder(intermediate_dim=128)(inputs=x)\n",
        "# x = keras_nlp.layers.FNetEncoder(intermediate_dim=128)(inputs=x)\n",
        "# x = keras_nlp.layers.FNetEncoder(intermediate_dim=128)(inputs=x)\n",
        "\n",
        "\n",
        "# x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "# x = keras.layers.Dropout(0.1)(x)\n",
        "# outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "# fnet_classifier = keras.Model(input_ids, outputs, name=\"fnet_classifier\")\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    #optimizer=tf.keras.optimizers.SGD(),\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    metrics=[\"accuracy\"] #tf.keras.metrics.CategoricalAccuracy()\n",
        ")\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "549\n"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "batch_size = 32\n",
        "eval_batch_size = 32\n",
        "\n",
        "train_data_size = len(X_test)\n",
        "steps_per_epoch = int(train_data_size / batch_size)\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "warmup_steps = int(0.1 * num_train_steps)\n",
        "initial_learning_rate=2e-5\n",
        "\n",
        "print(steps_per_epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-21 19:00:18.899569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [70388]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-07-21 19:00:18.899839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [70388,3]\n",
            "\t [[{{node Placeholder/_2}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-21 19:00:21.217646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-21 19:00:24.686806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
            "2023-07-21 19:00:25.670534: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\twhile inferring type of node 'cond_40/output/_23'\n",
            "2023-07-21 19:00:27.403011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8903\n",
            "2023-07-21 19:00:27.638806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "2023-07-21 19:00:27.651698: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fdb80c2a8c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-07-21 19:00:27.651738: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
            "2023-07-21 19:00:27.663120: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-07-21 19:00:27.802928: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2023-07-21 19:00:27.886270: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 884/2200 [===========>..................] - ETA: 5:47 - loss: 1.1196 - accuracy: 0.4625"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history2 \u001b[39m=\u001b[39m model2\u001b[39m.\u001b[39;49mfit(train_dataset1, \n\u001b[1;32m      2\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mtest_dataset1,\n\u001b[1;32m      4\u001b[0m                     \u001b[39m#validation_steps=30,\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m                     \u001b[39m#class_weight = {0:w0,1:w1,2:w2},\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m                     \u001b[39m#use_multiprocessing = True,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m                     \u001b[39m#workers = 5\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m                     )\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history2 = model2.fit(train_dataset1, \n",
        "                    epochs=100,\n",
        "                    validation_data=val_dataset1,\n",
        "                    validation_steps=30,\n",
        "                    steps_per_epoch=steps_per_epoch\n",
        "                    #class_weight = {0:w0,1:w1,2:w2},\n",
        "                    #use_multiprocessing = True,\n",
        "                    #workers = 5\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 27s 195ms/step - loss: 1.0181 - accuracy: 0.5425\n",
            "Test Loss: 1.0181047916412354\n",
            "Test Accuracy: 0.5425048470497131\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model2.evaluate(test_dataset1)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/138 [..............................] - ETA: 5s - loss: 1.0176 - accuracy: 0.5469"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 27s 196ms/step - loss: 1.0181 - accuracy: 0.5425\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.0181047916412354, 0.5425048470497131]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.evaluate(test_dataset1, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1.1905199944972993)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history2, 'accuracy')\n",
        "plt.ylim(None, 1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history2, 'loss')\n",
        "plt.ylim(0, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "137\n"
          ]
        }
      ],
      "source": [
        "# Set up epochs and steps\n",
        "epochs = 3\n",
        "batch_size = 32\n",
        "eval_batch_size = 32\n",
        "\n",
        "train_data_size = len(X_test)\n",
        "steps_per_epoch = int(train_data_size / BATCH_SIZE)\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "warmup_steps = int(0.1 * num_train_steps)\n",
        "initial_learning_rate=2e-5\n",
        "\n",
        "print(steps_per_epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model2' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#save model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mmkdir -p saved_model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model2\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39msaved_model/FNetEncoder_Model\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
          ]
        }
      ],
      "source": [
        "#save model\n",
        "!mkdir -p saved_model\n",
        "model2.save('saved_model/FNetEncoder_Model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "No file or directory found at saved_model/FNetEncoder_Model.h5",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Recreate the exact same model, including its weights and the optimizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m new_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39msaved_model/FNetEncoder_Model.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Show the model architecture\u001b[39;00m\n\u001b[1;32m      5\u001b[0m new_model\u001b[39m.\u001b[39msummary()\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/keras/saving/saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    205\u001b[0m         filepath,\n\u001b[1;32m    206\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    207\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[1;32m    208\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    213\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    214\u001b[0m )\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/Repos/Jira_Oracle/.venv/lib/python3.11/site-packages/keras/saving/legacy/save.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m         )\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    235\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[1;32m    236\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[1;32m    237\u001b[0m         )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at saved_model/FNetEncoder_Model.h5"
          ]
        }
      ],
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('saved_model/FNetEncoder_Model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset2 = train_dataset.shuffle(BUFFER_SIZE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset2 = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset2 = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "VOCAB_SIZE = 2500 #1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset2.map(lambda text, label: text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "input_shape = (X_train.shape[0],None,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 26 Complete [00h 03m 05s]\n",
            "multi_objective: 0.4712008237838745\n",
            "\n",
            "Best multi_objective So Far: 0.40578633546829224\n",
            "Total elapsed time: 00h 41m 04s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def hyper_class(hp):\n",
        "    model = keras.Sequential([\n",
        "        encoder,\n",
        "        tf.keras.layers.Embedding(len(encoder.get_vocabulary()), output_dim=hp.Int(\"output_dim\", min_value=8, max_value=128, step=32), mask_zero=True),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(4)),\n",
        "        keras_nlp.layers.FNetEncoder(intermediate_dim=hp.Int(\"intermediate_dim1\", min_value=8, max_value=128, step=32),\n",
        "                                    dropout=hp.Float(\"dropout1\", 0.1, 0.8, sampling=\"log\")),\n",
        "        keras_nlp.layers.FNetEncoder(intermediate_dim=hp.Int(\"intermediate_dim2\", min_value=8, max_value=128, step=32),\n",
        "                                    dropout=hp.Float(\"dropout2\", 0.1, 0.8, sampling=\"log\")),\n",
        "        keras_nlp.layers.FNetEncoder(intermediate_dim=hp.Int(\"intermediate_dim3\", min_value=8, max_value=128, step=32),\n",
        "                                    dropout=hp.Float(\"dropout3\", 0.1, 0.8, sampling=\"log\")),\n",
        "        tf.keras.layers.Dropout(rate=hp.Float(\"rate\", 0.1, 0.99, sampling=\"log\")),\n",
        "        tf.keras.layers.Dense(3, activation='softmax'),\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")), \n",
        "        loss=\"categorical_crossentropy\", \n",
        "        metrics=[\"accuracy\",\"crossentropy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "tuner = keras_tuner.Hyperband(\n",
        "    hypermodel=hyper_class,\n",
        "    # Objective is one of the keys.\n",
        "    # Maximize the negative MAE, equivalent to minimize MAE.\n",
        "    objective=['val_accuracy', 'val_crossentropy'],\n",
        "    max_epochs=20,\n",
        "    directory=\"saved_model\",\n",
        "    project_name=\"classif_hypertuning\",\n",
        ")\n",
        "\n",
        "tuner.search(x=X_train[:1000], y=y_train_cat[:1000], validation_data=(X_val[:1000], y_val_cat[:1000]), callbacks = [callback])\n",
        "best_model = tuner.get_best_models()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.build(input_shape=(None, 28, 28))\n",
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner.results_summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63349\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'build setup instal last time modul instal novemb modul need tri build python api separ'>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 1.], dtype=float32)>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-21 20:00:35.075349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [63349,3]\n",
            "\t [[{{node Placeholder/_2}}]]\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset.cardinality().numpy())\n",
        "for element in train_dataset:\n",
        "    print(element)\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_classification_rnn.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
